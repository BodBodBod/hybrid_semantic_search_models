# Сравнительный анализ лексических и векторных подходов в задаче семантического поиска на русском языке

Данный репозиторий содержит код и экспериментальные материалы для ВКР, посвящённой сравнению лексических и векторных подходов в задаче семантического поиска на русском языке. В проекте реализованы Retrieval-компоненты системы информационного поиска, проводится анализ качества извлечения релевантных документов, а также исследуются гибридные методы объединения лексических и трансформерных моделей.

Код проекта расположен в папке `python_project`.

## Модули

### `Retrievers.py`

Содержит реализации трёх основных классов для извлечения релевантных документов:
- `TransformerRetriever` — поиск с использованием трансформеров;
- `LexicalRetriever` — поиск с использованием `BM25`, `TF-IDF`;
- `HybridScorer` — комбинированный подход с объединение сигналов от моделей `BM25`, `TF-IDF` и `Transformer` в виде линейной комбинации с весами `α`, `β`, `γ` соответственно.

### `model_quality.py`

- `grid_search_weights()` — перебор весов (`α`, `β`, `γ`) для гибридной модели с целью максимизации метрики `Recall@5`;
- `make_recall_function()` — функция, вычисляющая `Recall@k` для заданной трансформерной модели `TransformerRetriever`.

### `pipline_functions.py`

Функции для проведения экспериментов над трансформерными моделями, включая:
- инициализацию лексических и трансформерных моделей;
- формирование / сериализацию / загрузку эмбеддингов;
- grid search по весам `α`, `β`, `γ` гибридной модели;
- проверку статистической значимости различий между гибридным и трансформерным подходом по метрике `Recall@5`. 

### `plotting.py`

- Функция для визуализации зависимости `Recall@5` от весов `α`, `β`, `γ` с помощью 3D-графиков для визуального анализа.
<img src="https://github.com/BodBodBod/diploma/blob/main/python_project/experiments_results/bert-base-multilingual-cased.png?raw=true" style="width:60%; max-width:100%;" alt="Пример визуализации для модели bert-base-multilingual-cased">

---

## Данные

Для экспериментов используется синтетический корпус [**RuHNP**](https://huggingface.co/datasets/deepvk/ru-HNP#ruhnp), включающий:
- 2000 текстов-запросов на русском языке из Wikipedia,
- по 5 синонимов и 5 антонимов к каждому запросу, сгенерированных при помощи `gpt-3.5-turbo`.

---

## Запуск экспериментов

Пример запуска экспериментов показан в `pipeline.ipynb`
Notebook адаптирован под Google Colab, импортируются соответствующие библиотеки и производится mount.
Поэтому для запуска экспериментов рекомендуется:
1. Импортировать проект на Google Drive - "Мой диск";
2. Загрузить в папку transformer_embeddings файлы из Dropbox (ссылка в папке);
3. Запустить `pipeline.ipynb`.
